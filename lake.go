package lake

import (
	"context"
	"encoding/json"
	"fmt"
	"sync"

	"github.com/hkloudou/lake/v2/internal/config"
	"github.com/hkloudou/lake/v2/internal/index"
	"github.com/hkloudou/lake/v2/internal/merge"
	"github.com/hkloudou/lake/v2/internal/snapshot"
	"github.com/hkloudou/lake/v2/internal/storage"
	"github.com/redis/go-redis/v9"
)

// Client is the main interface for Lake v2
type Client struct {
	rdb       *redis.Client
	writer    *index.Writer
	reader    *index.Reader
	merger    *merge.Engine
	configMgr *config.Manager

	// Lazy-loaded components
	mu      sync.RWMutex
	storage storage.Storage
	snapMgr *snapshot.Manager
	config  *config.Config
}

// Option is a function that configures the client
type Option struct {
	Storage storage.Storage
}

// NewLake creates a new Lake client with the given Redis URL
// Config is loaded lazily on first operation
func NewLake(metaUrl string, opts ...func(*Option)) *Client {
	// Parse Redis URL
	redisOpt, err := redis.ParseURL(metaUrl)
	if err != nil {
		// Fallback to treating it as an address
		redisOpt = &redis.Options{
			Addr: metaUrl,
		}
	}

	rdb := redis.NewClient(redisOpt)

	// Apply options
	option := &Option{}
	for _, opt := range opts {
		opt(option)
	}

	writer := index.NewWriter(rdb)
	reader := index.NewReader(rdb)
	merger := merge.NewEngine()
	configMgr := config.NewManager(rdb)

	client := &Client{
		rdb:       rdb,
		writer:    writer,
		reader:    reader,
		merger:    merger,
		configMgr: configMgr,
		storage:   option.Storage, // May be nil, will be loaded lazily
	}

	return client
}

// ensureInitialized ensures storage and snapMgr are initialized
// Loads config from Redis if not already loaded
func (c *Client) ensureInitialized(ctx context.Context) error {
	c.mu.RLock()
	if c.storage != nil && c.snapMgr != nil {
		c.mu.RUnlock()
		return nil
	}
	c.mu.RUnlock()

	c.mu.Lock()
	defer c.mu.Unlock()

	// Double-check after acquiring write lock
	if c.storage != nil && c.snapMgr != nil {
		return nil
	}

	// Load config and initialize storage if not provided
	if c.storage == nil {
		// Load config from Redis if not already loaded
		if c.config == nil {
			cfg, err := c.configMgr.Load(ctx)
			if err != nil {
				return fmt.Errorf("failed to load config from Redis (lake.setting): %w", err)
			}
			c.config = cfg
		}

		// Create storage from config - must succeed, no fallback
		stor, err := c.config.CreateStorage()
		if err != nil {
			return fmt.Errorf("failed to create %s storage: %w", c.config.Storage, err)
		}
		c.storage = stor

		// Set index prefix based on config: Storage:Name
		prefix := fmt.Sprintf("%s:%s", c.config.Storage, c.config.Name)
		c.writer.SetPrefix(prefix)
		c.reader.SetPrefix(prefix)
	}

	// Initialize snapshot manager
	if c.snapMgr == nil {
		c.snapMgr = snapshot.NewManager(c.storage, c.reader, c.writer)
	}

	return nil
}

// WriteRequest represents a write request
type WriteRequest struct {
	Catalog   string          // Catalog name
	Field     string          // JSON path (e.g., "user.profile.name")
	Value     any             // Value to write
	MergeType index.MergeType // Merge strategy (Replace or Merge)
}

// WriteResult represents the write result
type WriteResult struct {
	TsSeqID   string // Generated timestamp_seqid
	Timestamp int64  // Unix timestamp
	SeqID     int64  // Sequence ID
}

// Write writes data to the catalog
// Timestamp and sequence ID are auto-generated by Redis
func (c *Client) Write(ctx context.Context, req WriteRequest) (*WriteResult, error) {
	// Ensure initialized before operation
	if err := c.ensureInitialized(ctx); err != nil {
		return nil, err
	}

	// Marshal value to JSON
	data, err := json.Marshal(req.Value)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal value: %w", err)
	}

	// Generate time+seqid and add to index (atomically)
	tsSeq, err := c.writer.AddWithTimeSeq(ctx, req.Catalog, req.Field, req.MergeType)
	if err != nil {
		return nil, fmt.Errorf("failed to add to index: %w", err)
	}

	// Write to storage with filename: catalog/{ts}_{seqid}_{mergetype}.json
	if c.storage == nil {
		return nil, fmt.Errorf("storage not initialized")
	}
	key := storage.MakeDataKey(req.Catalog, tsSeq.String(), int(req.MergeType))
	if err := c.storage.Put(ctx, key, data); err != nil {
		// Rollback: remove from Redis index (best effort)
		// TODO: implement proper rollback mechanism
		return nil, fmt.Errorf("failed to write to storage: %w", err)
	}

	return &WriteResult{
		TsSeqID:   tsSeq.String(),
		Timestamp: tsSeq.Timestamp,
		SeqID:     tsSeq.SeqID,
	}, nil
}

// ReadRequest represents a read request
type ReadRequest struct {
	Catalog      string // Catalog name
	GenerateSnap bool   // Whether to generate snapshot automatically
}

// ReadResult represents the read result
type ReadResult struct {
	Data     map[string]any     // Merged JSON data
	Snapshot *snapshot.Snapshot // Snapshot info (if generated or used)
	Entries  []index.ReadResult // Raw entries (for debugging)
}

// mergeEntries merges entries into baseData
// This is the single source of truth for data merging
func (c *Client) mergeEntries(ctx context.Context, catalog string, baseData map[string]any, entries []index.ReadResult) (map[string]any, error) {
	merged := baseData
	for _, entry := range entries {
		// Read JSON from storage using new filename format
		key := storage.MakeDataKey(catalog, entry.TsSeqID, int(entry.MergeType))
		data, err := c.storage.Get(ctx, key)
		if err != nil {
			continue // Skip missing data
		}

		var value any
		if err := json.Unmarshal(data, &value); err != nil {
			continue // Skip invalid JSON
		}

		// Merge using the strategy from entry
		// TODO: implement deep merge strategy for MergeTypeMerge
		var strategy merge.Strategy
		switch entry.MergeType {
		case index.MergeTypeReplace:
			strategy = merge.StrategySet // Replace: always overwrite
		case index.MergeTypeMerge:
			strategy = merge.StrategySet // Merge: for now, same as set (TODO: deep merge)
		default:
			strategy = merge.StrategySet
		}

		merged, err = c.merger.Merge(merged, entry.Field, value, strategy)
		if err != nil {
			return nil, fmt.Errorf("failed to merge: %w", err)
		}
	}
	return merged, nil
}

func (c *Client) Info(ctx context.Context, catalog string) {

}

// Read reads and merges data from the catalog
func (c *Client) Read(ctx context.Context, req ReadRequest) (*ReadResult, error) {
	// Ensure initialized before operation
	if err := c.ensureInitialized(ctx); err != nil {
		return nil, err
	}

	// Try to get existing snapshot
	snap, err := c.snapMgr.GetLatest(ctx, req.Catalog, false)
	if err != nil {
		return nil, fmt.Errorf("failed to get snapshot: %w", err)
	}

	var allEntries []index.ReadResult

	if snap != nil {
		// With snapshot: read all entries in the time range [0, stopTsSeq]
		// and incremental entries after stopTsSeq
		tsSeq, err := index.ParseTimeSeqID(snap.StopTsSeq)
		if err != nil {
			return nil, fmt.Errorf("failed to parse snapshot stopTsSeq: %w", err)
		}

		// Read all entries (will merge all data from scratch)
		allEntries, err = c.reader.ReadAll(ctx, req.Catalog)
		if err != nil {
			return nil, fmt.Errorf("failed to read all data: %w", err)
		}

		// TODO: Optimize by reading snapshot data range + incremental
		// For now, we rebuild from all entries
		_ = tsSeq
	} else {
		// No snapshot, read all
		allEntries, err = c.reader.ReadAll(ctx, req.Catalog)
		if err != nil {
			return nil, fmt.Errorf("failed to read all data: %w", err)
		}
	}

	// Merge data from all entries (rebuild from scratch)
	baseData := make(map[string]any)
	entries := allEntries

	// Merge data (single source of truth)
	merged, err := c.mergeEntries(ctx, req.Catalog, baseData, entries)
	if err != nil {
		return nil, err
	}

	result := &ReadResult{
		Data:     merged,
		Snapshot: snap,
		Entries:  allEntries, // Return all entries for debugging
	}

	// Generate snapshot if requested
	if req.GenerateSnap && len(allEntries) > 0 {
		// Determine startTsSeq and stopTsSeq
		var startTsSeq string
		if snap != nil {
			// Continue from previous snapshot
			startTsSeq = snap.StopTsSeq
		} else {
			// First snapshot, start from 0_0
			startTsSeq = "0_0"
		}

		// Use the last entry's TsSeqID as stop point
		lastEntry := allEntries[len(allEntries)-1]
		stopTsSeq := lastEntry.TsSeqID

		// Parse score from stopTsSeq
		tsSeq, err := index.ParseTimeSeqID(stopTsSeq)
		if err == nil {
			score := tsSeq.Score()

			// Save snapshot metadata (time range only, no data)
			newSnap, err := c.snapMgr.Save(ctx, req.Catalog, startTsSeq, stopTsSeq, score)
			if err == nil {
				result.Snapshot = newSnap
			}
			// Ignore error, not critical
		}
	}

	return result, nil
}

// GetConfig returns the current config (loads from Redis if needed)
// DEPRECATED: Temporarily disabled. DO NOT DELETE this code.
// Will be re-enabled after API stabilization.
/*
func (c *Client) GetConfig(ctx context.Context) (*config.Config, error) {
	c.mu.RLock()
	if c.config != nil {
		cfg := c.config
		c.mu.RUnlock()
		return cfg, nil
	}
	c.mu.RUnlock()

	// Load config
	cfg, err := c.configMgr.Load(ctx)
	if err != nil {
		return nil, err
	}

	c.mu.Lock()
	c.config = cfg
	c.mu.Unlock()

	return cfg, nil
}
*/

// UpdateConfig updates the config in Redis
// DEPRECATED: Temporarily disabled. DO NOT DELETE this code.
// Will be re-enabled after storage reinitialization logic is implemented.
/*
func (c *Client) UpdateConfig(ctx context.Context, cfg *config.Config) error {
	if err := c.configMgr.Save(ctx, cfg); err != nil {
		return err
	}

	// Update cached config
	c.mu.Lock()
	c.config = cfg
	// TODO: Reinitialize storage based on new config
	c.mu.Unlock()

	return nil
}
*/
